{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import  plot_loss_curves, compare_historys, walk_through_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves(history):\n",
    "  \"\"\"\n",
    "  Returns separate loss curves for training and validation metrics.\n",
    "  Args:\n",
    "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
    "  \"\"\" \n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  accuracy = history.history['accuracy']\n",
    "  val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "  epochs = range(len(history.history['loss']))\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(epochs, loss, label='training_loss')\n",
    "  plt.plot(epochs, val_loss, label='val_loss')\n",
    "  plt.title('Loss')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend()\n",
    "\n",
    "  # Plot accuracy\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
    "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
    "  plt.title('Accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk_through_dir(\"BasicFinalDatabase\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"BanglaLekha/train/\"\n",
    "test_dir = \"BanglaLekha/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72500 files belonging to 50 classes.\n",
      "Found 12502 files belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "train_data_= tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE)\n",
    "                                                                                \n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required modules for model creation\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Setup data augmentation\n",
    "data_augmentation = Sequential([\n",
    "  #preprocessing.RandomFlip(\"horizontal\"), # randomly flip images on horizontal edge\n",
    "  #preprocessing.RandomRotation(0.2), # randomly rotate images by a specific amount\n",
    "  preprocessing.RandomHeight(0.2), # randomly adjust the height of an image by a specific amount\n",
    "  preprocessing.RandomWidth(0.2), # randomly adjust the width of an image by a specific amount\n",
    "  #preprocessing.RandomZoom(0.2), # randomly zoom into an image\n",
    "  preprocessing.Rescaling(1./255) \n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2dwithbn(x,\n",
    "              filters,\n",
    "              kernel_size,\n",
    "              strides=1,\n",
    "              padding='same',\n",
    "              activation='relu',\n",
    "              use_bias=False,\n",
    "              name=None):\n",
    "  \"\"\"Utility function to apply conv + BN.\n",
    "  Args:\n",
    "    x: input tensor.\n",
    "    filters: filters in `Conv2D`.\n",
    "    kernel_size: kernel size as in `Conv2D`.\n",
    "    strides: strides in `Conv2D`.\n",
    "    padding: padding mode in `Conv2D`.\n",
    "    activation: activation in `Conv2D`.\n",
    "    use_bias: whether to use a bias in `Conv2D`.\n",
    "    name: name of the ops; will become `name + '_ac'` for the activation\n",
    "        and `name + '_bn'` for the batch norm layer.\n",
    "  Returns:\n",
    "    Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
    "  \"\"\"\n",
    "  x = layers.Conv2D(\n",
    "      filters,\n",
    "      kernel_size,\n",
    "      strides=strides,\n",
    "      padding=padding,\n",
    "      use_bias=use_bias,\n",
    "      name=name)(\n",
    "          x)\n",
    "  if not use_bias:\n",
    "    bn_axis = 1 if backend.image_data_format() == 'channels_first' else 3\n",
    "    bn_name = None if name is None else name + '_bn'\n",
    "    x = layers.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
    "  if activation is not None:\n",
    "    ac_name = None if name is None else name + '_ac'\n",
    "    x = layers.Activation(activation, name=ac_name)(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_resnet_block(x, scale, block_type, block_idx, activation='relu'):\n",
    "  \"\"\"Adds an Inception-ResNet block.\n",
    "  This function builds 3 types of Inception-ResNet blocks mentioned\n",
    "  in the paper, controlled by the `block_type` argument (which is the\n",
    "  block name used in the official TF-slim implementation):\n",
    "  - Inception-ResNet-A: `block_type='block35'`\n",
    "  - Inception-ResNet-B: `block_type='block17'`\n",
    "  - Inception-ResNet-C: `block_type='block8'`\n",
    "  Args:\n",
    "    x: input tensor.\n",
    "    scale: scaling factor to scale the residuals (i.e., the output of passing\n",
    "      `x` through an inception module) before adding them to the shortcut\n",
    "      branch. Let `r` be the output from the residual branch, the output of this\n",
    "      block will be `x + scale * r`.\n",
    "    block_type: `'block35'`, `'block17'` or `'block8'`, determines the network\n",
    "      structure in the residual branch.\n",
    "    block_idx: an `int` used for generating layer names. The Inception-ResNet\n",
    "      blocks are repeated many times in this network. We use `block_idx` to\n",
    "      identify each of the repetitions. For example, the first\n",
    "      Inception-ResNet-A block will have `block_type='block35', block_idx=0`,\n",
    "      and the layer names will have a common prefix `'block35_0'`.\n",
    "    activation: activation function to use at the end of the block (see\n",
    "      [activations](../activations.md)). When `activation=None`, no activation\n",
    "      is applied\n",
    "      (i.e., \"linear\" activation: `a(x) = x`).\n",
    "  Returns:\n",
    "      Output tensor for the block.\n",
    "  Raises:\n",
    "    ValueError: if `block_type` is not one of `'block35'`,\n",
    "      `'block17'` or `'block8'`.\n",
    "  \"\"\"\n",
    "  if block_type == 'block35':\n",
    "    branch_0 = conv2dwithbn(x, 32, 1)\n",
    "    branch_1 = conv2dwithbn(x, 32, 1)\n",
    "    branch_1 = conv2dwithbn(branch_1, 32, 3)\n",
    "    branch_2 = conv2dwithbn(x, 32, 1)\n",
    "    branch_2 = conv2dwithbn(branch_2, 48, 3)\n",
    "    branch_2 = conv2dwithbn(branch_2, 64, 3)\n",
    "    branches = [branch_0, branch_1, branch_2]\n",
    "  elif block_type == 'block17':\n",
    "    branch_0 = conv2dwithbn(x, 192, 1)\n",
    "    branch_1 = conv2dwithbn(x, 128, 1)\n",
    "    branch_1 = conv2dwithbn(branch_1, 160, [1, 7])\n",
    "    branch_1 = conv2dwithbn(branch_1, 192, [7, 1])\n",
    "    branches = [branch_0, branch_1]\n",
    "  elif block_type == 'block8':\n",
    "    branch_0 = conv2dwithbn(x, 192, 1)\n",
    "    branch_1 = conv2dwithbn(x, 192, 1)\n",
    "    branch_1 = conv2dwithbn(branch_1, 224, [1, 3])\n",
    "    branch_1 = conv2dwithbn(branch_1, 256, [3, 1])\n",
    "    branches = [branch_0, branch_1]\n",
    "  else:\n",
    "    raise ValueError('Unknown Inception-ResNet block type. '\n",
    "                     'Expects \"block35\", \"block17\" or \"block8\", '\n",
    "                     'but got: ' + str(block_type))\n",
    "\n",
    "  block_name = block_type + '_' + str(block_idx)\n",
    "  channel_axis = 1 if backend.image_data_format() == 'channels_first' else 3\n",
    "  mixed = layers.Concatenate(\n",
    "      axis=channel_axis, name=block_name + '_mixed')(\n",
    "          branches)\n",
    "  up = conv2dwithbn(\n",
    "      mixed,\n",
    "      backend.int_shape(x)[channel_axis],\n",
    "      1,\n",
    "      activation=None,\n",
    "      use_bias=True,\n",
    "      name=block_name + '_conv')\n",
    "\n",
    "  x = layers.Lambda(\n",
    "      lambda inputs, scale: inputs[0] + inputs[1] * scale,\n",
    "      output_shape=backend.int_shape(x)[1:],\n",
    "      arguments={'scale': scale},\n",
    "      name=block_name)([x, up])\n",
    "  if activation is not None:\n",
    "    x = layers.Activation(activation, name=block_name + '_ac')(x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apakNet(img_input):\n",
    "    #stem block\n",
    "    x = conv2dwithbn(img_input, 32, 3, strides=2, padding='valid')\n",
    "    x = conv2dwithbn(x, 32, 3, padding='valid')\n",
    "    x = conv2dwithbn(x, 64, 3)\n",
    "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "    x = conv2dwithbn(x, 80, 1, padding='valid')\n",
    "    x = conv2dwithbn(x, 192, 3, padding='valid')\n",
    "    x = layers.MaxPooling2D(3, strides=2)(x)\n",
    "    #inception block-A\n",
    "    branch_0 =conv2dwithbn(x, 96, 1)\n",
    "    branch_1 =conv2dwithbn(x, 48, 1)\n",
    "    branch_1 =conv2dwithbn(branch_1, 64, 5)\n",
    "    branch_2 =conv2dwithbn(x, 64, 1)\n",
    "    branch_2 =conv2dwithbn(branch_2, 96, 3)\n",
    "    branch_2 =conv2dwithbn(branch_2, 96, 3)\n",
    "    branch_pool = layers.AveragePooling2D(3, strides=1, padding='same')(x)\n",
    "    branch_pool =conv2dwithbn(branch_pool, 64, 1)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else 3\n",
    "    x = layers.Concatenate(axis=channel_axis, name='mixed_5b')(branches)\n",
    "    for block_idx in range(1, 3):\n",
    "        x = inception_resnet_block(\n",
    "            x, scale=0.17, block_type='block35', block_idx=block_idx)\n",
    "    branch_0 = conv2dwithbn(x, 384, 3, strides=2, padding='valid')\n",
    "    branch_1 = conv2dwithbn(x, 256, 1)\n",
    "    branch_1 = conv2dwithbn(branch_1, 256, 3)\n",
    "    branch_1 = conv2dwithbn(branch_1, 384, 3, strides=2, padding='valid')\n",
    "    branch_pool = layers.MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branches = [branch_0, branch_1, branch_pool]\n",
    "    x = layers.Concatenate(axis=channel_axis, name='mixed_6a')(branches)\n",
    "    for block_idx in range(1,5):\n",
    "        x = inception_resnet_block(\n",
    "            x, scale=0.1, block_type='block17', block_idx=block_idx)\n",
    "    branch_0 = conv2dwithbn(x, 256, 1)\n",
    "    branch_0 = conv2dwithbn(branch_0, 384, 3, strides=2, padding='valid')\n",
    "    branch_1 = conv2dwithbn(x, 256, 1)\n",
    "    branch_1 = conv2dwithbn(branch_1, 288, 3, strides=2, padding='valid')\n",
    "    branch_2 = conv2dwithbn(x, 256, 1)\n",
    "    branch_2 = conv2dwithbn(branch_2, 288, 3)\n",
    "    branch_2 = conv2dwithbn(branch_2, 320, 3, strides=2, padding='valid')\n",
    "    branch_pool = layers.MaxPooling2D(3, strides=2, padding='valid')(x)\n",
    "    branches = [branch_0, branch_1, branch_2, branch_pool]\n",
    "    x = layers.Concatenate(axis=channel_axis, name='mixed_7a')(branches)\n",
    "    for block_idx in range(1, 2):\n",
    "        x = inception_resnet_block(\n",
    "            x, scale=0.2, block_type='block8', block_idx=block_idx)\n",
    "    x = inception_resnet_block(\n",
    "            x, scale=1., activation=None, block_type='block8', block_idx=2)\n",
    "    x = conv2dwithbn(x, 1536, 1, name='conv_7b')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "x = data_augmentation(inputs)\n",
    "x=apakNet(x)\n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\n",
    "# flattened_before_dense = layers.Flatten()(x)\n",
    "dense1 = layers.Dense(1024, activation='relu', name='firstDenseLayer', kernel_regularizer= tf.keras.regularizers.l2(0.001))(x)\n",
    "dropout1 =layers.Dropout(0.5, name='FirstDropOutLayer')(dense1)\n",
    "dense2 = layers.Dense(512, activation='relu', name='SecondDenseLayer', kernel_regularizer= tf.keras.regularizers.l2(0.001))(dropout1)\n",
    "# dropout1 =layers.Dropout(0.5, name='FirstDropOutLayer')(dense2)\n",
    "dense3 = layers.Dense(256, activation='relu', name='ThirdDenseLayer', kernel_regularizer= tf.keras.regularizers.l2(0.001))(dense2)\n",
    "        \n",
    "# dense4 = layers.Dense(128, activation='relu', name='FourthDenseLayer')(dense3)\n",
    "outputs = layers.Dense(len(train_data_.class_names), activation=\"softmax\", name=\"output_layer\")(dense3)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_layer (InputLayer)       [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " data_augmentation (Sequential)  (None, None, None,   0          ['input_layer[0][0]']            \n",
      "                                3)                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, None, None,   864         ['data_augmentation[0][0]']      \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, None, None,   96         ['conv2d[0][0]']                 \n",
      " alization)                     32)                                                               \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, None, None,   0           ['batch_normalization[0][0]']    \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, None, None,   9216        ['activation[0][0]']             \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, None, None,   96         ['conv2d_1[0][0]']               \n",
      " rmalization)                   32)                                                               \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, None, None,   0           ['batch_normalization_1[0][0]']  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, None, None,   18432       ['activation_1[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, None, None,   192        ['conv2d_2[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, None, None,   0           ['batch_normalization_2[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, None, None,   0           ['activation_2[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, None, None,   5120        ['max_pooling2d[0][0]']          \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, None, None,   240        ['conv2d_3[0][0]']               \n",
      " rmalization)                   80)                                                               \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, None, None,   0           ['batch_normalization_3[0][0]']  \n",
      "                                80)                                                               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, None, None,   138240      ['activation_3[0][0]']           \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, None, None,   576        ['conv2d_4[0][0]']               \n",
      " rmalization)                   192)                                                              \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, None, None,   0           ['batch_normalization_4[0][0]']  \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, None, None,   0          ['activation_4[0][0]']           \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, None, None,   12288       ['max_pooling2d_1[0][0]']        \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, None, None,   192        ['conv2d_8[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, None, None,   0           ['batch_normalization_8[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, None, None,   9216        ['max_pooling2d_1[0][0]']        \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, None, None,   55296       ['activation_8[0][0]']           \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, None, None,   144        ['conv2d_6[0][0]']               \n",
      " rmalization)                   48)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, None, None,   288        ['conv2d_9[0][0]']               \n",
      " rmalization)                   96)                                                               \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, None, None,   0           ['batch_normalization_6[0][0]']  \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, None, None,   0           ['batch_normalization_9[0][0]']  \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, None, None,   0          ['max_pooling2d_1[0][0]']        \n",
      " ing2D)                         192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, None, None,   18432       ['max_pooling2d_1[0][0]']        \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, None, None,   76800       ['activation_6[0][0]']           \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, None, None,   82944       ['activation_9[0][0]']           \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, None, None,   12288       ['average_pooling2d[0][0]']      \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, None, None,   288        ['conv2d_5[0][0]']               \n",
      " rmalization)                   96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, None, None,   192        ['conv2d_7[0][0]']               \n",
      " rmalization)                   64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, None, None,   288        ['conv2d_10[0][0]']              \n",
      " ormalization)                  96)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, None, None,   192        ['conv2d_11[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, None, None,   0           ['batch_normalization_5[0][0]']  \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, None, None,   0           ['batch_normalization_7[0][0]']  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, None, None,   0           ['batch_normalization_10[0][0]'] \n",
      "                                96)                                                               \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, None, None,   0           ['batch_normalization_11[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " mixed_5b (Concatenate)         (None, None, None,   0           ['activation_5[0][0]',           \n",
      "                                320)                              'activation_7[0][0]',           \n",
      "                                                                  'activation_10[0][0]',          \n",
      "                                                                  'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, None, None,   10240       ['mixed_5b[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, None, None,   96         ['conv2d_15[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, None, None,   0           ['batch_normalization_15[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, None, None,   10240       ['mixed_5b[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, None, None,   13824       ['activation_15[0][0]']          \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, None, None,   96         ['conv2d_13[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, None, None,   144        ['conv2d_16[0][0]']              \n",
      " ormalization)                  48)                                                               \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, None, None,   0           ['batch_normalization_13[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, None, None,   0           ['batch_normalization_16[0][0]'] \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, None, None,   10240       ['mixed_5b[0][0]']               \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, None, None,   9216        ['activation_13[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, None, None,   27648       ['activation_16[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, None, None,   96         ['conv2d_12[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, None, None,   96         ['conv2d_14[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, None, None,   192        ['conv2d_17[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, None, None,   0           ['batch_normalization_12[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, None, None,   0           ['batch_normalization_14[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, None, None,   0           ['batch_normalization_17[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " block35_1_mixed (Concatenate)  (None, None, None,   0           ['activation_12[0][0]',          \n",
      "                                128)                              'activation_14[0][0]',          \n",
      "                                                                  'activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " block35_1_conv (Conv2D)        (None, None, None,   41280       ['block35_1_mixed[0][0]']        \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " block35_1 (Lambda)             (None, None, None,   0           ['mixed_5b[0][0]',               \n",
      "                                320)                              'block35_1_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_1_ac (Activation)      (None, None, None,   0           ['block35_1[0][0]']              \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, None, None,   10240       ['block35_1_ac[0][0]']           \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, None, None,   96         ['conv2d_21[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, None, None,   0           ['batch_normalization_21[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, None, None,   10240       ['block35_1_ac[0][0]']           \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, None, None,   13824       ['activation_21[0][0]']          \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, None, None,   96         ['conv2d_19[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, None, None,   144        ['conv2d_22[0][0]']              \n",
      " ormalization)                  48)                                                               \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, None, None,   0           ['batch_normalization_19[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, None, None,   0           ['batch_normalization_22[0][0]'] \n",
      "                                48)                                                               \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, None, None,   10240       ['block35_1_ac[0][0]']           \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, None, None,   9216        ['activation_19[0][0]']          \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, None, None,   27648       ['activation_22[0][0]']          \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, None, None,   96         ['conv2d_18[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, None, None,   96         ['conv2d_20[0][0]']              \n",
      " ormalization)                  32)                                                               \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, None, None,   192        ['conv2d_23[0][0]']              \n",
      " ormalization)                  64)                                                               \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, None, None,   0           ['batch_normalization_18[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, None, None,   0           ['batch_normalization_20[0][0]'] \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, None, None,   0           ['batch_normalization_23[0][0]'] \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " block35_2_mixed (Concatenate)  (None, None, None,   0           ['activation_18[0][0]',          \n",
      "                                128)                              'activation_20[0][0]',          \n",
      "                                                                  'activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " block35_2_conv (Conv2D)        (None, None, None,   41280       ['block35_2_mixed[0][0]']        \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " block35_2 (Lambda)             (None, None, None,   0           ['block35_1_ac[0][0]',           \n",
      "                                320)                              'block35_2_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block35_2_ac (Activation)      (None, None, None,   0           ['block35_2[0][0]']              \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, None, None,   81920       ['block35_2_ac[0][0]']           \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, None, None,   768        ['conv2d_25[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, None, None,   0           ['batch_normalization_25[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, None, None,   589824      ['activation_25[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, None, None,   768        ['conv2d_26[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, None, None,   0           ['batch_normalization_26[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, None, None,   1105920     ['block35_2_ac[0][0]']           \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, None, None,   884736      ['activation_26[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, None, None,   1152       ['conv2d_24[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, None, None,   1152       ['conv2d_27[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, None, None,   0           ['batch_normalization_24[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, None, None,   0           ['batch_normalization_27[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, None, None,   0          ['block35_2_ac[0][0]']           \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " mixed_6a (Concatenate)         (None, None, None,   0           ['activation_24[0][0]',          \n",
      "                                1088)                             'activation_27[0][0]',          \n",
      "                                                                  'max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, None, None,   139264      ['mixed_6a[0][0]']               \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, None, None,   384        ['conv2d_29[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, None, None,   0           ['batch_normalization_29[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, None, None,   143360      ['activation_29[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, None, None,   480        ['conv2d_30[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, None, None,   0           ['batch_normalization_30[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, None, None,   208896      ['mixed_6a[0][0]']               \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, None, None,   215040      ['activation_30[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, None, None,   576        ['conv2d_28[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, None, None,   576        ['conv2d_31[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, None, None,   0           ['batch_normalization_28[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, None, None,   0           ['batch_normalization_31[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block17_1_mixed (Concatenate)  (None, None, None,   0           ['activation_28[0][0]',          \n",
      "                                384)                              'activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " block17_1_conv (Conv2D)        (None, None, None,   418880      ['block17_1_mixed[0][0]']        \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " block17_1 (Lambda)             (None, None, None,   0           ['mixed_6a[0][0]',               \n",
      "                                1088)                             'block17_1_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_1_ac (Activation)      (None, None, None,   0           ['block17_1[0][0]']              \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, None, None,   139264      ['block17_1_ac[0][0]']           \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, None, None,   384        ['conv2d_33[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, None, None,   0           ['batch_normalization_33[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, None, None,   143360      ['activation_33[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, None, None,   480        ['conv2d_34[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, None, None,   0           ['batch_normalization_34[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, None, None,   208896      ['block17_1_ac[0][0]']           \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, None, None,   215040      ['activation_34[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, None, None,   576        ['conv2d_32[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, None, None,   576        ['conv2d_35[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, None, None,   0           ['batch_normalization_32[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, None, None,   0           ['batch_normalization_35[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block17_2_mixed (Concatenate)  (None, None, None,   0           ['activation_32[0][0]',          \n",
      "                                384)                              'activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " block17_2_conv (Conv2D)        (None, None, None,   418880      ['block17_2_mixed[0][0]']        \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " block17_2 (Lambda)             (None, None, None,   0           ['block17_1_ac[0][0]',           \n",
      "                                1088)                             'block17_2_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_2_ac (Activation)      (None, None, None,   0           ['block17_2[0][0]']              \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, None, None,   139264      ['block17_2_ac[0][0]']           \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, None, None,   384        ['conv2d_37[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, None, None,   0           ['batch_normalization_37[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, None, None,   143360      ['activation_37[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, None, None,   480        ['conv2d_38[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, None, None,   0           ['batch_normalization_38[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, None, None,   208896      ['block17_2_ac[0][0]']           \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, None, None,   215040      ['activation_38[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, None, None,   576        ['conv2d_36[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, None, None,   576        ['conv2d_39[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, None, None,   0           ['batch_normalization_36[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, None, None,   0           ['batch_normalization_39[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block17_3_mixed (Concatenate)  (None, None, None,   0           ['activation_36[0][0]',          \n",
      "                                384)                              'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " block17_3_conv (Conv2D)        (None, None, None,   418880      ['block17_3_mixed[0][0]']        \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " block17_3 (Lambda)             (None, None, None,   0           ['block17_2_ac[0][0]',           \n",
      "                                1088)                             'block17_3_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_3_ac (Activation)      (None, None, None,   0           ['block17_3[0][0]']              \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, None, None,   139264      ['block17_3_ac[0][0]']           \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, None, None,   384        ['conv2d_41[0][0]']              \n",
      " ormalization)                  128)                                                              \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, None, None,   0           ['batch_normalization_41[0][0]'] \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, None, None,   143360      ['activation_41[0][0]']          \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, None, None,   480        ['conv2d_42[0][0]']              \n",
      " ormalization)                  160)                                                              \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, None, None,   0           ['batch_normalization_42[0][0]'] \n",
      "                                160)                                                              \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, None, None,   208896      ['block17_3_ac[0][0]']           \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, None, None,   215040      ['activation_42[0][0]']          \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, None, None,   576        ['conv2d_40[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, None, None,   576        ['conv2d_43[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, None, None,   0           ['batch_normalization_40[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, None, None,   0           ['batch_normalization_43[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " block17_4_mixed (Concatenate)  (None, None, None,   0           ['activation_40[0][0]',          \n",
      "                                384)                              'activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " block17_4_conv (Conv2D)        (None, None, None,   418880      ['block17_4_mixed[0][0]']        \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " block17_4 (Lambda)             (None, None, None,   0           ['block17_3_ac[0][0]',           \n",
      "                                1088)                             'block17_4_conv[0][0]']         \n",
      "                                                                                                  \n",
      " block17_4_ac (Activation)      (None, None, None,   0           ['block17_4[0][0]']              \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, None, None,   278528      ['block17_4_ac[0][0]']           \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, None, None,   768        ['conv2d_48[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, None, None,   0           ['batch_normalization_48[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, None, None,   278528      ['block17_4_ac[0][0]']           \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, None, None,   278528      ['block17_4_ac[0][0]']           \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, None, None,   663552      ['activation_48[0][0]']          \n",
      "                                288)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, None, None,   768        ['conv2d_44[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, None, None,   768        ['conv2d_46[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, None, None,   864        ['conv2d_49[0][0]']              \n",
      " ormalization)                  288)                                                              \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, None, None,   0           ['batch_normalization_44[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, None, None,   0           ['batch_normalization_46[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, None, None,   0           ['batch_normalization_49[0][0]'] \n",
      "                                288)                                                              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, None, None,   884736      ['activation_44[0][0]']          \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, None, None,   663552      ['activation_46[0][0]']          \n",
      "                                288)                                                              \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, None, None,   829440      ['activation_49[0][0]']          \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, None, None,   1152       ['conv2d_45[0][0]']              \n",
      " ormalization)                  384)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, None, None,   864        ['conv2d_47[0][0]']              \n",
      " ormalization)                  288)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, None, None,   960        ['conv2d_50[0][0]']              \n",
      " ormalization)                  320)                                                              \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, None, None,   0           ['batch_normalization_45[0][0]'] \n",
      "                                384)                                                              \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, None, None,   0           ['batch_normalization_47[0][0]'] \n",
      "                                288)                                                              \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, None, None,   0           ['batch_normalization_50[0][0]'] \n",
      "                                320)                                                              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, None, None,   0          ['block17_4_ac[0][0]']           \n",
      "                                1088)                                                             \n",
      "                                                                                                  \n",
      " mixed_7a (Concatenate)         (None, None, None,   0           ['activation_45[0][0]',          \n",
      "                                2080)                             'activation_47[0][0]',          \n",
      "                                                                  'activation_50[0][0]',          \n",
      "                                                                  'max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, None, None,   399360      ['mixed_7a[0][0]']               \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, None, None,   576        ['conv2d_52[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, None, None,   0           ['batch_normalization_52[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, None, None,   129024      ['activation_52[0][0]']          \n",
      "                                224)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, None, None,   672        ['conv2d_53[0][0]']              \n",
      " ormalization)                  224)                                                              \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, None, None,   0           ['batch_normalization_53[0][0]'] \n",
      "                                224)                                                              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, None, None,   399360      ['mixed_7a[0][0]']               \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, None, None,   172032      ['activation_53[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, None, None,   576        ['conv2d_51[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, None, None,   768        ['conv2d_54[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, None, None,   0           ['batch_normalization_51[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, None, None,   0           ['batch_normalization_54[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " block8_1_mixed (Concatenate)   (None, None, None,   0           ['activation_51[0][0]',          \n",
      "                                448)                              'activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " block8_1_conv (Conv2D)         (None, None, None,   933920      ['block8_1_mixed[0][0]']         \n",
      "                                2080)                                                             \n",
      "                                                                                                  \n",
      " block8_1 (Lambda)              (None, None, None,   0           ['mixed_7a[0][0]',               \n",
      "                                2080)                             'block8_1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " block8_1_ac (Activation)       (None, None, None,   0           ['block8_1[0][0]']               \n",
      "                                2080)                                                             \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, None, None,   399360      ['block8_1_ac[0][0]']            \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, None, None,   576        ['conv2d_56[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, None, None,   0           ['batch_normalization_56[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, None, None,   129024      ['activation_56[0][0]']          \n",
      "                                224)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, None, None,   672        ['conv2d_57[0][0]']              \n",
      " ormalization)                  224)                                                              \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, None, None,   0           ['batch_normalization_57[0][0]'] \n",
      "                                224)                                                              \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, None, None,   399360      ['block8_1_ac[0][0]']            \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, None, None,   172032      ['activation_57[0][0]']          \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, None, None,   576        ['conv2d_55[0][0]']              \n",
      " ormalization)                  192)                                                              \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, None, None,   768        ['conv2d_58[0][0]']              \n",
      " ormalization)                  256)                                                              \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, None, None,   0           ['batch_normalization_55[0][0]'] \n",
      "                                192)                                                              \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, None, None,   0           ['batch_normalization_58[0][0]'] \n",
      "                                256)                                                              \n",
      "                                                                                                  \n",
      " block8_2_mixed (Concatenate)   (None, None, None,   0           ['activation_55[0][0]',          \n",
      "                                448)                              'activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " block8_2_conv (Conv2D)         (None, None, None,   933920      ['block8_2_mixed[0][0]']         \n",
      "                                2080)                                                             \n",
      "                                                                                                  \n",
      " block8_2 (Lambda)              (None, None, None,   0           ['block8_1_ac[0][0]',            \n",
      "                                2080)                             'block8_2_conv[0][0]']          \n",
      "                                                                                                  \n",
      " conv_7b (Conv2D)               (None, None, None,   3194880     ['block8_2[0][0]']               \n",
      "                                1536)                                                             \n",
      "                                                                                                  \n",
      " conv_7b_bn (BatchNormalization  (None, None, None,   4608       ['conv_7b[0][0]']                \n",
      " )                              1536)                                                             \n",
      "                                                                                                  \n",
      " conv_7b_ac (Activation)        (None, None, None,   0           ['conv_7b_bn[0][0]']             \n",
      "                                1536)                                                             \n",
      "                                                                                                  \n",
      " global_average_pooling (Global  (None, 1536)        0           ['conv_7b_ac[0][0]']             \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " firstDenseLayer (Dense)        (None, 1024)         1573888     ['global_average_pooling[0][0]'] \n",
      "                                                                                                  \n",
      " FirstDropOutLayer (Dropout)    (None, 1024)         0           ['firstDenseLayer[0][0]']        \n",
      "                                                                                                  \n",
      " SecondDenseLayer (Dense)       (None, 512)          524800      ['FirstDropOutLayer[0][0]']      \n",
      "                                                                                                  \n",
      " ThirdDenseLayer (Dense)        (None, 256)          131328      ['SecondDenseLayer[0][0]']       \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 50)           12850       ['ThirdDenseLayer[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,262,738\n",
      "Trainable params: 21,241,362\n",
      "Non-trainable params: 21,376\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import plot_model\n",
    "# plot_model(model, 'apakNet.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "2266/2266 [==============================] - 842s 367ms/step - loss: 2.6642 - accuracy: 0.6731 - precision: 0.8687 - recall: 0.5719 - f1_m: 0.6342 - val_loss: 2.3715 - val_accuracy: 0.6536 - val_precision: 0.6701 - val_recall: 0.6272 - val_f1_m: 0.6453\n",
      "Epoch 2/80\n",
      "2266/2266 [==============================] - 396s 175ms/step - loss: 1.4133 - accuracy: 0.8854 - precision: 0.9243 - recall: 0.8560 - f1_m: 0.8882 - val_loss: 1.1423 - val_accuracy: 0.9159 - val_precision: 0.9277 - val_recall: 0.9052 - val_f1_m: 0.9153\n",
      "Epoch 3/80\n",
      "2266/2266 [==============================] - 315s 139ms/step - loss: 1.0204 - accuracy: 0.9076 - precision: 0.9369 - recall: 0.8864 - f1_m: 0.9106 - val_loss: 0.7651 - val_accuracy: 0.9472 - val_precision: 0.9562 - val_recall: 0.9402 - val_f1_m: 0.9477\n",
      "Epoch 4/80\n",
      "2266/2266 [==============================] - 289s 128ms/step - loss: 0.7663 - accuracy: 0.9201 - precision: 0.9447 - recall: 0.9023 - f1_m: 0.9227 - val_loss: 0.6009 - val_accuracy: 0.9477 - val_precision: 0.9561 - val_recall: 0.9391 - val_f1_m: 0.9471\n",
      "Epoch 5/80\n",
      "2266/2266 [==============================] - 281s 124ms/step - loss: 0.6064 - accuracy: 0.9280 - precision: 0.9504 - recall: 0.9119 - f1_m: 0.9305 - val_loss: 0.4778 - val_accuracy: 0.9520 - val_precision: 0.9628 - val_recall: 0.9472 - val_f1_m: 0.9547\n",
      "Epoch 6/80\n",
      "2266/2266 [==============================] - 278s 123ms/step - loss: 0.5032 - accuracy: 0.9318 - precision: 0.9523 - recall: 0.9185 - f1_m: 0.9348 - val_loss: 0.3777 - val_accuracy: 0.9607 - val_precision: 0.9688 - val_recall: 0.9547 - val_f1_m: 0.9612\n",
      "Epoch 7/80\n",
      "2266/2266 [==============================] - 275s 121ms/step - loss: 0.4285 - accuracy: 0.9387 - precision: 0.9572 - recall: 0.9265 - f1_m: 0.9413 - val_loss: 0.3847 - val_accuracy: 0.9510 - val_precision: 0.9632 - val_recall: 0.9450 - val_f1_m: 0.9538\n",
      "Epoch 8/80\n",
      "2266/2266 [==============================] - 274s 121ms/step - loss: 0.3818 - accuracy: 0.9414 - precision: 0.9588 - recall: 0.9299 - f1_m: 0.9439 - val_loss: 0.3521 - val_accuracy: 0.9440 - val_precision: 0.9477 - val_recall: 0.9380 - val_f1_m: 0.9427\n",
      "Epoch 9/80\n",
      "2266/2266 [==============================] - 272s 120ms/step - loss: 0.3421 - accuracy: 0.9453 - precision: 0.9617 - recall: 0.9350 - f1_m: 0.9479 - val_loss: 0.2817 - val_accuracy: 0.9612 - val_precision: 0.9684 - val_recall: 0.9580 - val_f1_m: 0.9631\n",
      "Epoch 10/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.3108 - accuracy: 0.9484 - precision: 0.9627 - recall: 0.9383 - f1_m: 0.9502 - val_loss: 0.2524 - val_accuracy: 0.9623 - val_precision: 0.9690 - val_recall: 0.9585 - val_f1_m: 0.9636\n",
      "Epoch 11/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.2890 - accuracy: 0.9520 - precision: 0.9654 - recall: 0.9430 - f1_m: 0.9539 - val_loss: 0.2472 - val_accuracy: 0.9617 - val_precision: 0.9674 - val_recall: 0.9596 - val_f1_m: 0.9634\n",
      "Epoch 12/80\n",
      "2266/2266 [==============================] - 271s 120ms/step - loss: 0.2687 - accuracy: 0.9541 - precision: 0.9670 - recall: 0.9458 - f1_m: 0.9562 - val_loss: 0.2891 - val_accuracy: 0.9531 - val_precision: 0.9586 - val_recall: 0.9477 - val_f1_m: 0.9528\n",
      "Epoch 13/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.2506 - accuracy: 0.9575 - precision: 0.9690 - recall: 0.9498 - f1_m: 0.9591 - val_loss: 0.2870 - val_accuracy: 0.9483 - val_precision: 0.9568 - val_recall: 0.9429 - val_f1_m: 0.9496\n",
      "Epoch 14/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.2387 - accuracy: 0.9582 - precision: 0.9694 - recall: 0.9508 - f1_m: 0.9599 - val_loss: 0.2124 - val_accuracy: 0.9677 - val_precision: 0.9718 - val_recall: 0.9650 - val_f1_m: 0.9683\n",
      "Epoch 15/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.2237 - accuracy: 0.9618 - precision: 0.9714 - recall: 0.9551 - f1_m: 0.9630 - val_loss: 0.2743 - val_accuracy: 0.9596 - val_precision: 0.9641 - val_recall: 0.9558 - val_f1_m: 0.9597\n",
      "Epoch 16/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.2174 - accuracy: 0.9619 - precision: 0.9716 - recall: 0.9553 - f1_m: 0.9632 - val_loss: 0.2359 - val_accuracy: 0.9628 - val_precision: 0.9643 - val_recall: 0.9601 - val_f1_m: 0.9622\n",
      "Epoch 17/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.2033 - accuracy: 0.9645 - precision: 0.9734 - recall: 0.9585 - f1_m: 0.9658 - val_loss: 0.1711 - val_accuracy: 0.9763 - val_precision: 0.9794 - val_recall: 0.9741 - val_f1_m: 0.9767\n",
      "Epoch 18/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1931 - accuracy: 0.9666 - precision: 0.9751 - recall: 0.9606 - f1_m: 0.9677 - val_loss: 0.2448 - val_accuracy: 0.9601 - val_precision: 0.9616 - val_recall: 0.9580 - val_f1_m: 0.9598\n",
      "Epoch 19/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.1875 - accuracy: 0.9674 - precision: 0.9753 - recall: 0.9620 - f1_m: 0.9685 - val_loss: 0.2820 - val_accuracy: 0.9456 - val_precision: 0.9537 - val_recall: 0.9434 - val_f1_m: 0.9483\n",
      "Epoch 20/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.1804 - accuracy: 0.9693 - precision: 0.9769 - recall: 0.9635 - f1_m: 0.9700 - val_loss: 0.2060 - val_accuracy: 0.9688 - val_precision: 0.9734 - val_recall: 0.9661 - val_f1_m: 0.9695\n",
      "Epoch 21/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1749 - accuracy: 0.9696 - precision: 0.9768 - recall: 0.9644 - f1_m: 0.9704 - val_loss: 0.1779 - val_accuracy: 0.9720 - val_precision: 0.9756 - val_recall: 0.9704 - val_f1_m: 0.9729\n",
      "Epoch 22/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1679 - accuracy: 0.9708 - precision: 0.9775 - recall: 0.9660 - f1_m: 0.9717 - val_loss: 0.1683 - val_accuracy: 0.9747 - val_precision: 0.9773 - val_recall: 0.9736 - val_f1_m: 0.9754\n",
      "Epoch 23/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1610 - accuracy: 0.9722 - precision: 0.9785 - recall: 0.9673 - f1_m: 0.9728 - val_loss: 0.1961 - val_accuracy: 0.9661 - val_precision: 0.9702 - val_recall: 0.9644 - val_f1_m: 0.9672\n",
      "Epoch 24/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.1572 - accuracy: 0.9730 - precision: 0.9791 - recall: 0.9686 - f1_m: 0.9737 - val_loss: 0.1616 - val_accuracy: 0.9774 - val_precision: 0.9794 - val_recall: 0.9752 - val_f1_m: 0.9772\n",
      "Epoch 25/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.1519 - accuracy: 0.9742 - precision: 0.9800 - recall: 0.9702 - f1_m: 0.9750 - val_loss: 0.1823 - val_accuracy: 0.9731 - val_precision: 0.9751 - val_recall: 0.9704 - val_f1_m: 0.9727\n",
      "Epoch 26/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.1478 - accuracy: 0.9757 - precision: 0.9811 - recall: 0.9714 - f1_m: 0.9762 - val_loss: 0.1880 - val_accuracy: 0.9644 - val_precision: 0.9696 - val_recall: 0.9634 - val_f1_m: 0.9663\n",
      "Epoch 27/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1430 - accuracy: 0.9760 - precision: 0.9814 - recall: 0.9723 - f1_m: 0.9768 - val_loss: 0.1487 - val_accuracy: 0.9828 - val_precision: 0.9848 - val_recall: 0.9801 - val_f1_m: 0.9824\n",
      "Epoch 28/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.1391 - accuracy: 0.9778 - precision: 0.9826 - recall: 0.9741 - f1_m: 0.9782 - val_loss: 0.1865 - val_accuracy: 0.9688 - val_precision: 0.9734 - val_recall: 0.9671 - val_f1_m: 0.9702\n",
      "Epoch 29/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.1374 - accuracy: 0.9773 - precision: 0.9820 - recall: 0.9736 - f1_m: 0.9777 - val_loss: 0.2058 - val_accuracy: 0.9693 - val_precision: 0.9718 - val_recall: 0.9671 - val_f1_m: 0.9693\n",
      "Epoch 30/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1335 - accuracy: 0.9778 - precision: 0.9824 - recall: 0.9746 - f1_m: 0.9784 - val_loss: 0.1809 - val_accuracy: 0.9731 - val_precision: 0.9751 - val_recall: 0.9709 - val_f1_m: 0.9729\n",
      "Epoch 31/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.1274 - accuracy: 0.9798 - precision: 0.9838 - recall: 0.9763 - f1_m: 0.9800 - val_loss: 0.1892 - val_accuracy: 0.9698 - val_precision: 0.9724 - val_recall: 0.9671 - val_f1_m: 0.9696\n",
      "Epoch 32/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1277 - accuracy: 0.9793 - precision: 0.9834 - recall: 0.9761 - f1_m: 0.9797 - val_loss: 0.2488 - val_accuracy: 0.9569 - val_precision: 0.9589 - val_recall: 0.9542 - val_f1_m: 0.9564\n",
      "Epoch 33/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.1225 - accuracy: 0.9804 - precision: 0.9843 - recall: 0.9773 - f1_m: 0.9807 - val_loss: 0.1958 - val_accuracy: 0.9682 - val_precision: 0.9728 - val_recall: 0.9650 - val_f1_m: 0.9688\n",
      "Epoch 34/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1209 - accuracy: 0.9809 - precision: 0.9845 - recall: 0.9779 - f1_m: 0.9811 - val_loss: 0.2152 - val_accuracy: 0.9682 - val_precision: 0.9713 - val_recall: 0.9666 - val_f1_m: 0.9689\n",
      "Epoch 35/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1184 - accuracy: 0.9821 - precision: 0.9855 - recall: 0.9791 - f1_m: 0.9823 - val_loss: 0.2054 - val_accuracy: 0.9682 - val_precision: 0.9713 - val_recall: 0.9666 - val_f1_m: 0.9689\n",
      "Epoch 36/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.1140 - accuracy: 0.9819 - precision: 0.9857 - recall: 0.9787 - f1_m: 0.9821 - val_loss: 0.2044 - val_accuracy: 0.9725 - val_precision: 0.9735 - val_recall: 0.9704 - val_f1_m: 0.9719\n",
      "Epoch 37/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.1131 - accuracy: 0.9821 - precision: 0.9853 - recall: 0.9795 - f1_m: 0.9823 - val_loss: 0.1711 - val_accuracy: 0.9752 - val_precision: 0.9757 - val_recall: 0.9731 - val_f1_m: 0.9744\n",
      "Epoch 38/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1080 - accuracy: 0.9838 - precision: 0.9867 - recall: 0.9814 - f1_m: 0.9840 - val_loss: 0.1913 - val_accuracy: 0.9741 - val_precision: 0.9768 - val_recall: 0.9736 - val_f1_m: 0.9752\n",
      "Epoch 39/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1090 - accuracy: 0.9830 - precision: 0.9863 - recall: 0.9802 - f1_m: 0.9832 - val_loss: 0.1991 - val_accuracy: 0.9698 - val_precision: 0.9714 - val_recall: 0.9688 - val_f1_m: 0.9700\n",
      "Epoch 40/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1074 - accuracy: 0.9837 - precision: 0.9865 - recall: 0.9811 - f1_m: 0.9837 - val_loss: 0.1698 - val_accuracy: 0.9747 - val_precision: 0.9784 - val_recall: 0.9741 - val_f1_m: 0.9762\n",
      "Epoch 41/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.1032 - accuracy: 0.9847 - precision: 0.9872 - recall: 0.9823 - f1_m: 0.9847 - val_loss: 0.2007 - val_accuracy: 0.9693 - val_precision: 0.9729 - val_recall: 0.9671 - val_f1_m: 0.9699\n",
      "Epoch 42/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.1016 - accuracy: 0.9851 - precision: 0.9878 - recall: 0.9828 - f1_m: 0.9852 - val_loss: 0.1972 - val_accuracy: 0.9731 - val_precision: 0.9736 - val_recall: 0.9725 - val_f1_m: 0.9730\n",
      "Epoch 43/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.1010 - accuracy: 0.9854 - precision: 0.9881 - recall: 0.9829 - f1_m: 0.9854 - val_loss: 0.1799 - val_accuracy: 0.9720 - val_precision: 0.9767 - val_recall: 0.9704 - val_f1_m: 0.9735\n",
      "Epoch 44/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.0980 - accuracy: 0.9855 - precision: 0.9878 - recall: 0.9832 - f1_m: 0.9855 - val_loss: 0.2138 - val_accuracy: 0.9677 - val_precision: 0.9697 - val_recall: 0.9671 - val_f1_m: 0.9684\n",
      "Epoch 45/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0952 - accuracy: 0.9865 - precision: 0.9888 - recall: 0.9843 - f1_m: 0.9865 - val_loss: 0.1755 - val_accuracy: 0.9763 - val_precision: 0.9778 - val_recall: 0.9747 - val_f1_m: 0.9762\n",
      "Epoch 46/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0964 - accuracy: 0.9855 - precision: 0.9879 - recall: 0.9833 - f1_m: 0.9855 - val_loss: 0.1911 - val_accuracy: 0.9731 - val_precision: 0.9746 - val_recall: 0.9720 - val_f1_m: 0.9733\n",
      "Epoch 47/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0917 - accuracy: 0.9868 - precision: 0.9888 - recall: 0.9848 - f1_m: 0.9868 - val_loss: 0.2119 - val_accuracy: 0.9693 - val_precision: 0.9724 - val_recall: 0.9682 - val_f1_m: 0.9702\n",
      "Epoch 48/80\n",
      "2266/2266 [==============================] - 269s 118ms/step - loss: 0.0945 - accuracy: 0.9859 - precision: 0.9881 - recall: 0.9837 - f1_m: 0.9859 - val_loss: 0.2098 - val_accuracy: 0.9693 - val_precision: 0.9713 - val_recall: 0.9666 - val_f1_m: 0.9689\n",
      "Epoch 49/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.0919 - accuracy: 0.9865 - precision: 0.9889 - recall: 0.9846 - f1_m: 0.9867 - val_loss: 0.1618 - val_accuracy: 0.9774 - val_precision: 0.9774 - val_recall: 0.9768 - val_f1_m: 0.9771\n",
      "Epoch 50/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0906 - accuracy: 0.9870 - precision: 0.9893 - recall: 0.9851 - f1_m: 0.9871 - val_loss: 0.1835 - val_accuracy: 0.9725 - val_precision: 0.9730 - val_recall: 0.9714 - val_f1_m: 0.9722\n",
      "Epoch 51/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.0899 - accuracy: 0.9870 - precision: 0.9889 - recall: 0.9849 - f1_m: 0.9868 - val_loss: 0.2025 - val_accuracy: 0.9731 - val_precision: 0.9762 - val_recall: 0.9714 - val_f1_m: 0.9738\n",
      "Epoch 52/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0852 - accuracy: 0.9884 - precision: 0.9906 - recall: 0.9867 - f1_m: 0.9886 - val_loss: 0.1968 - val_accuracy: 0.9693 - val_precision: 0.9724 - val_recall: 0.9688 - val_f1_m: 0.9706\n",
      "Epoch 53/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0851 - accuracy: 0.9880 - precision: 0.9899 - recall: 0.9860 - f1_m: 0.9879 - val_loss: 0.1422 - val_accuracy: 0.9828 - val_precision: 0.9828 - val_recall: 0.9828 - val_f1_m: 0.9828\n",
      "Epoch 54/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0845 - accuracy: 0.9879 - precision: 0.9898 - recall: 0.9862 - f1_m: 0.9880 - val_loss: 0.2214 - val_accuracy: 0.9704 - val_precision: 0.9730 - val_recall: 0.9693 - val_f1_m: 0.9711\n",
      "Epoch 55/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0834 - accuracy: 0.9883 - precision: 0.9905 - recall: 0.9865 - f1_m: 0.9885 - val_loss: 0.1909 - val_accuracy: 0.9725 - val_precision: 0.9730 - val_recall: 0.9720 - val_f1_m: 0.9725\n",
      "Epoch 56/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0817 - accuracy: 0.9888 - precision: 0.9906 - recall: 0.9871 - f1_m: 0.9888 - val_loss: 0.1732 - val_accuracy: 0.9741 - val_precision: 0.9757 - val_recall: 0.9736 - val_f1_m: 0.9746\n",
      "Epoch 57/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0812 - accuracy: 0.9888 - precision: 0.9905 - recall: 0.9872 - f1_m: 0.9888 - val_loss: 0.1598 - val_accuracy: 0.9806 - val_precision: 0.9811 - val_recall: 0.9790 - val_f1_m: 0.9800\n",
      "Epoch 58/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.0774 - accuracy: 0.9894 - precision: 0.9911 - recall: 0.9877 - f1_m: 0.9894 - val_loss: 0.1951 - val_accuracy: 0.9698 - val_precision: 0.9724 - val_recall: 0.9693 - val_f1_m: 0.9708\n",
      "Epoch 59/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0792 - accuracy: 0.9887 - precision: 0.9903 - recall: 0.9868 - f1_m: 0.9885 - val_loss: 0.2188 - val_accuracy: 0.9709 - val_precision: 0.9746 - val_recall: 0.9709 - val_f1_m: 0.9726\n",
      "Epoch 60/80\n",
      "2266/2266 [==============================] - 269s 118ms/step - loss: 0.0778 - accuracy: 0.9896 - precision: 0.9913 - recall: 0.9879 - f1_m: 0.9895 - val_loss: 0.1672 - val_accuracy: 0.9784 - val_precision: 0.9811 - val_recall: 0.9774 - val_f1_m: 0.9792\n",
      "Epoch 61/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0761 - accuracy: 0.9897 - precision: 0.9912 - recall: 0.9880 - f1_m: 0.9896 - val_loss: 0.1708 - val_accuracy: 0.9784 - val_precision: 0.9784 - val_recall: 0.9779 - val_f1_m: 0.9782\n",
      "Epoch 62/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.0761 - accuracy: 0.9901 - precision: 0.9918 - recall: 0.9886 - f1_m: 0.9902 - val_loss: 0.1669 - val_accuracy: 0.9768 - val_precision: 0.9773 - val_recall: 0.9763 - val_f1_m: 0.9768\n",
      "Epoch 63/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0742 - accuracy: 0.9902 - precision: 0.9916 - recall: 0.9885 - f1_m: 0.9900 - val_loss: 0.2038 - val_accuracy: 0.9747 - val_precision: 0.9762 - val_recall: 0.9731 - val_f1_m: 0.9746\n",
      "Epoch 64/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.0745 - accuracy: 0.9896 - precision: 0.9912 - recall: 0.9882 - f1_m: 0.9897 - val_loss: 0.1876 - val_accuracy: 0.9763 - val_precision: 0.9778 - val_recall: 0.9741 - val_f1_m: 0.9759\n",
      "Epoch 65/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0745 - accuracy: 0.9901 - precision: 0.9917 - recall: 0.9885 - f1_m: 0.9901 - val_loss: 0.2031 - val_accuracy: 0.9725 - val_precision: 0.9740 - val_recall: 0.9704 - val_f1_m: 0.9721\n",
      "Epoch 66/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0713 - accuracy: 0.9907 - precision: 0.9923 - recall: 0.9892 - f1_m: 0.9907 - val_loss: 0.1806 - val_accuracy: 0.9731 - val_precision: 0.9746 - val_recall: 0.9725 - val_f1_m: 0.9735\n",
      "Epoch 67/80\n",
      "2266/2266 [==============================] - 266s 117ms/step - loss: 0.0722 - accuracy: 0.9905 - precision: 0.9919 - recall: 0.9891 - f1_m: 0.9905 - val_loss: 0.1672 - val_accuracy: 0.9763 - val_precision: 0.9768 - val_recall: 0.9752 - val_f1_m: 0.9760\n",
      "Epoch 68/80\n",
      "2266/2266 [==============================] - 263s 116ms/step - loss: 0.0705 - accuracy: 0.9910 - precision: 0.9924 - recall: 0.9896 - f1_m: 0.9910 - val_loss: 0.2292 - val_accuracy: 0.9677 - val_precision: 0.9692 - val_recall: 0.9677 - val_f1_m: 0.9684\n",
      "Epoch 69/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.0711 - accuracy: 0.9904 - precision: 0.9919 - recall: 0.9890 - f1_m: 0.9904 - val_loss: 0.1642 - val_accuracy: 0.9774 - val_precision: 0.9800 - val_recall: 0.9763 - val_f1_m: 0.9781\n",
      "Epoch 70/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0685 - accuracy: 0.9913 - precision: 0.9926 - recall: 0.9901 - f1_m: 0.9913 - val_loss: 0.1668 - val_accuracy: 0.9801 - val_precision: 0.9822 - val_recall: 0.9795 - val_f1_m: 0.9808\n",
      "Epoch 71/80\n",
      "2266/2266 [==============================] - 267s 118ms/step - loss: 0.0698 - accuracy: 0.9906 - precision: 0.9922 - recall: 0.9890 - f1_m: 0.9906 - val_loss: 0.1726 - val_accuracy: 0.9795 - val_precision: 0.9816 - val_recall: 0.9784 - val_f1_m: 0.9800\n",
      "Epoch 72/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0667 - accuracy: 0.9916 - precision: 0.9926 - recall: 0.9904 - f1_m: 0.9915 - val_loss: 0.1715 - val_accuracy: 0.9806 - val_precision: 0.9817 - val_recall: 0.9806 - val_f1_m: 0.9811\n",
      "Epoch 73/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.0691 - accuracy: 0.9904 - precision: 0.9917 - recall: 0.9889 - f1_m: 0.9903 - val_loss: 0.1866 - val_accuracy: 0.9758 - val_precision: 0.9768 - val_recall: 0.9752 - val_f1_m: 0.9760\n",
      "Epoch 74/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0658 - accuracy: 0.9916 - precision: 0.9929 - recall: 0.9904 - f1_m: 0.9916 - val_loss: 0.2010 - val_accuracy: 0.9725 - val_precision: 0.9736 - val_recall: 0.9725 - val_f1_m: 0.9731\n",
      "Epoch 75/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.0660 - accuracy: 0.9915 - precision: 0.9928 - recall: 0.9903 - f1_m: 0.9915 - val_loss: 0.2050 - val_accuracy: 0.9720 - val_precision: 0.9756 - val_recall: 0.9714 - val_f1_m: 0.9735\n",
      "Epoch 76/80\n",
      "2266/2266 [==============================] - 268s 118ms/step - loss: 0.0659 - accuracy: 0.9914 - precision: 0.9928 - recall: 0.9903 - f1_m: 0.9915 - val_loss: 0.1923 - val_accuracy: 0.9693 - val_precision: 0.9714 - val_recall: 0.9693 - val_f1_m: 0.9703\n",
      "Epoch 77/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.0665 - accuracy: 0.9912 - precision: 0.9924 - recall: 0.9900 - f1_m: 0.9912 - val_loss: 0.1792 - val_accuracy: 0.9747 - val_precision: 0.9773 - val_recall: 0.9736 - val_f1_m: 0.9754\n",
      "Epoch 78/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0651 - accuracy: 0.9914 - precision: 0.9926 - recall: 0.9901 - f1_m: 0.9913 - val_loss: 0.1601 - val_accuracy: 0.9779 - val_precision: 0.9800 - val_recall: 0.9763 - val_f1_m: 0.9781\n",
      "Epoch 79/80\n",
      "2266/2266 [==============================] - 269s 119ms/step - loss: 0.0624 - accuracy: 0.9924 - precision: 0.9936 - recall: 0.9911 - f1_m: 0.9923 - val_loss: 0.2211 - val_accuracy: 0.9682 - val_precision: 0.9687 - val_recall: 0.9682 - val_f1_m: 0.9685\n",
      "Epoch 80/80\n",
      "2266/2266 [==============================] - 270s 119ms/step - loss: 0.0648 - accuracy: 0.9912 - precision: 0.9927 - recall: 0.9900 - f1_m: 0.9913 - val_loss: 0.2240 - val_accuracy: 0.9736 - val_precision: 0.9746 - val_recall: 0.9731 - val_f1_m: 0.9738\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(.0001), # use Adam with default settings\n",
    "              metrics=[\"accuracy\",tf.keras.metrics.Precision(),tf.keras.metrics.Recall(),f1_m])\n",
    "\n",
    "# Fit\n",
    "history_1= model.fit(train_data_,\n",
    "                    epochs=80,\n",
    "                    batch_size=256,\n",
    "                    validation_data=test_data,\n",
    "                    validation_steps=int(0.15 * len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 43ms/step - loss: 0.1525 - accuracy: 0.9810 - precision: 0.9817 - recall: 0.9807 - f1_m: 0.9812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.15249784290790558,\n",
       " 0.9809630513191223,\n",
       " 0.9817439317703247,\n",
       " 0.9807230830192566,\n",
       " 0.9812243580818176]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_feature_extraction_model = model.evaluate(test_data)\n",
    "results_feature_extraction_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_curves(history_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 68). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: custom_model_cmaterDB/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: custom_model_cmaterDB/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('custom_model/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d008b4bc0a3786c69201b20685766a35718a627f54c0ab627a0e8b24ca85f462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
